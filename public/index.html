<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Reden-Beurteilungsroboter - Eroeffnungsrede</title>
  <link rel="stylesheet" href="./styles.css" />
</head>
<body>
  <div class="hero">
    <header>
      <p class="eyebrow">Eroeffnungsrede - Analyse & Feedback</p>
      <h1>Reden-Beurteilungsroboter</h1>
      <p class="lead">Lade dein Video hoch. Die Beurteilung erfolgt automatisch durch die App und optional durch KI.</p>
      <div class="hero-meta">
        <span>Offline‑first</span>
        <span>Datenschutzfreundlich</span>
        <span>Für 2–3 Minuten</span>
      </div>
    </header>
    <section class="upload-panel">
      <div class="card">
        <h2>1. Video hochladen</h2>
        <p>Die lokale Analyse startet automatisch nach dem Upload. Video wird nicht hochgeladen.</p>
        <input id="videoInput" type="file" accept="video/*" />
        <div class="video-wrap">
          <video id="videoPreview" controls playsinline></video>
        </div>
        <div class="meta" id="videoMeta">Noch kein Video geladen.</div>
        <div class="meta" id="analysisStatus">Warte auf Video.</div>
        <div class="meta" id="featureStatus">
          FaceDetector: wird geprueft · Audioanalyse: bereit · Keyframes: bereit
        </div>
      </div>
    </section>
  </div>

  <main>
    <section class="grid two">
      <div class="card">
        <h2>2. Videoanalyse & Score</h2>
        <div class="scoreboard">
          <div>
            <div class="label">Gesamtpunkte</div>
            <div class="value" id="totalScore">0.0</div>
            <div class="hint" id="scoreHint">Maximal 5 Punkte (gewichtete Teilbereiche).</div>
          </div>
          <div>
            <div class="label">Zeit</div>
            <div class="value" id="timeScore">–</div>
            <div class="hint" id="timeHint">Idealer Umfang: 2–3 Minuten.</div>
          </div>
          <div>
            <div class="label">Sprechtempo</div>
            <div class="value" id="tempoScore">–</div>
            <div class="hint">Geschätzt aus Audio-Rhythmus.</div>
          </div>
          <div>
            <div class="label">Pausenanteil</div>
            <div class="value" id="pauseScore">–</div>
            <div class="hint">Aus Audio automatisch erkannt.</div>
          </div>
        </div>
        <div class="scoreboard cv-board">
          <div>
            <div class="label">Blickkontakt (Proxy)</div>
            <div class="value" id="eyeScore">–</div>
            <div class="hint">Wenn Browser Face-Detection unterstützt.</div>
          </div>
          <div>
            <div class="label">Bewegungsenergie</div>
            <div class="value" id="gestureScore">–</div>
            <div class="hint">Veränderung zwischen Videoframes.</div>
          </div>
          <div>
            <div class="label">Gesicht erkannt</div>
            <div class="value" id="faceScore">–</div>
            <div class="hint">Anteil der Frames mit Gesicht.</div>
          </div>
        </div>
        <div class="actions">
          <button id="analyzeBtn" class="primary">Video erneut analysieren</button>
          <button id="downloadBtn" class="ghost">Bericht herunterladen</button>
        </div>
      </div>
    </section>

    <section class="card feedback">
      <h2>3. Lernfoerderliches Feedback</h2>
      <div id="feedback">
        <p>Starte die Analyse, um Feedback zu erhalten.</p>
      </div>
    </section>

    <section class="card ai">
      <h2>4. KI-Feedback (optional)</h2>
      <p>Fuer diese Funktion wird ein OpenAI-API-Key auf dem Server benoetigt. Die API bekommt Analysewerte und Video-Keyframes.</p>
      <div class="actions">
        <button id="aiBtn" class="primary">KI schaut Video (Keyframes) an</button>
      </div>
      <div class="meta" id="aiStatus">Noch keine KI‑Analyse.</div>
      <div id="aiFeedback"></div>
    </section>

    <section class="card tips">
      <h2>So funktioniert die Bewertung</h2>
      <ul>
        <li>Die App analysiert Dauer, Audio-Rhythmus, Bewegung und optional Blickkontakt im Video.</li>
        <li>Die Bewertung erfolgt automatisch aus diesen Messwerten.</li>
        <li>Optional kann KI mit Video-Keyframes zusaetzliches Feedback geben.</li>
      </ul>
    </section>
  </main>

  <footer>
    <p>Bereit für GitHub: Dieses Projekt besteht aus statischen Dateien und einem kleinen Express‑Server.</p>
  </footer>

  <script src="./app.js"></script>
</body>
</html>
